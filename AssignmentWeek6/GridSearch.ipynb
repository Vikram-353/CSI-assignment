{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80901251",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c278617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17137c",
   "metadata": {},
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wine dataset\n",
    "df=pd.read_csv(\"./train.csv\")\n",
    "X = df.drop('price_range', axis=1)\n",
    "y = df['price_range']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Feature scaling\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a887ce97",
   "metadata": {},
   "source": [
    "# Train Baseline Models and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77303789",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 12\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     13\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     15\u001b[0m     results[name] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: accuracy_score(y_test, y_pred),\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m: precision_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m'\u001b[39m: recall_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1-score\u001b[39m\u001b[38;5;124m'\u001b[39m: f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m     }\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1204\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m   1196\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1197\u001b[0m     X,\n\u001b[0;32m   1198\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1203\u001b[0m )\n\u001b[1;32m-> 1204\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m   1207\u001b[0m multi_class \u001b[38;5;241m=\u001b[39m _check_multi_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class, solver, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:218\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    210\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    217\u001b[0m ]:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=500),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "        'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "        'F1-score': f1_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nüîé Baseline Model Results:\")\n",
    "print(results_df.sort_values(by='F1-score', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7796ee",
   "metadata": {},
   "source": [
    " # Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f03ba3",
   "metadata": {},
   "source": [
    "GridSearchCV for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c418ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Best SVM via GridSearchCV:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00        12\n",
      "     class_1       0.93      1.00      0.97        14\n",
      "     class_2       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_svm = GridSearchCV(SVC(), param_grid_svm, cv=5, scoring='f1_weighted')\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "best_svm = grid_svm.best_estimator_\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "\n",
    "print(\"\\n‚úÖ Best SVM via GridSearchCV:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=wine.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b472d906",
   "metadata": {},
   "source": [
    "RandomizedSearchCV for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a4ab68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Best Random Forest via RandomizedSearchCV:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00        12\n",
      "     class_1       1.00      1.00      1.00        14\n",
      "     class_2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_dist_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rand_search_rf = RandomizedSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    scoring='f1_weighted',\n",
    "    random_state=42\n",
    ")\n",
    "rand_search_rf.fit(X_train, y_train)\n",
    "\n",
    "best_rf = rand_search_rf.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "print(\"\\n‚úÖ Best Random Forest via RandomizedSearchCV:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=wine.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b694d87",
   "metadata": {},
   "source": [
    "# Add Tuned Models to Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b993d5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Final Model Comparison:\n",
      "                     Accuracy  Precision    Recall  F1-score\n",
      "Random Forest        1.000000   1.000000  1.000000  1.000000\n",
      "Tuned RF             1.000000   1.000000  1.000000  1.000000\n",
      "Logistic Regression  0.972222   0.974074  0.972222  0.971970\n",
      "SVM                  0.972222   0.974074  0.972222  0.971970\n",
      "Tuned SVM            0.972222   0.974074  0.972222  0.971970\n",
      "Decision Tree        0.944444   0.944444  0.944444  0.944444\n"
     ]
    }
   ],
   "source": [
    "# Add tuned models to results\n",
    "results['Tuned SVM'] = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_svm),\n",
    "    'Precision': precision_score(y_test, y_pred_svm, average='weighted'),\n",
    "    'Recall': recall_score(y_test, y_pred_svm, average='weighted'),\n",
    "    'F1-score': f1_score(y_test, y_pred_svm, average='weighted')\n",
    "}\n",
    "\n",
    "results['Tuned RF'] = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'Precision': precision_score(y_test, y_pred_rf, average='weighted'),\n",
    "    'Recall': recall_score(y_test, y_pred_rf, average='weighted'),\n",
    "    'F1-score': f1_score(y_test, y_pred_rf, average='weighted')\n",
    "}\n",
    "\n",
    "# Final comparison\n",
    "final_results_df = pd.DataFrame(results).T\n",
    "print(\"\\nüèÜ Final Model Comparison:\")\n",
    "print(final_results_df.sort_values(by='F1-score', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f6d76c",
   "metadata": {},
   "source": [
    "# Interpretation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa2ec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚≠êÔ∏è The best performing model is: Random Forest\n"
     ]
    }
   ],
   "source": [
    "best_model_name = final_results_df['F1-score'].idxmax()\n",
    "print(f\"\\n‚≠êÔ∏è The best performing model is: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4385c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
